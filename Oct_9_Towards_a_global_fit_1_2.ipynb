{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generation and Analysis workshop\n",
        "## Wednesday Oct 9, 2024: Towards a Global Fit - part 1/2\n",
        "\n",
        "This tutorial shows minimal methods to fit for an instrumental noise model and a stochastic GW background. It is oultined as follows:\n",
        "\n",
        "0. Installation of required dependencies\n",
        "1. Orbit file generation\n",
        "2. Download GW TDI data from LDC and check them against PSD models\n",
        "3. Download noise TDI data from LDC and check them against PSD models\n",
        "4. Perform the estimation of noise parameters\n",
        "5. Perform the estimation of GW parameter\n",
        "6. Using more TDI channels (exercice)"
      ],
      "metadata": {
        "id": "nMrO4rmF7A8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Requirements\n",
        "Install and import the required packages"
      ],
      "metadata": {
        "id": "sgLbDLU46n_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LISA Constants\n",
        "!pip install lisaconstants\n",
        "# LISA Orbits\n",
        "!pip install lisaorbits\n",
        "# LISA Instrument\n",
        "!pip install lisainstrument\n",
        "# LISA GW Response\n",
        "!pip install lisagwresponse\n",
        "# pyTDI\n",
        "!pip install pytdi"
      ],
      "metadata": {
        "id": "eK7npoFxbW2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install a tool to compute phase transition spectra\n",
        "!pip install --upgrade git+https://dweir@bitbucket.org/dweir/ptplot.git\n",
        "# Install a corner plot tool\n",
        "!pip install corner\n",
        "# Install backgrounds analysis tool\n",
        "!pip install backgrounds"
      ],
      "metadata": {
        "id": "epzTbdfzbZZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install a sampler\n",
        "!git clone https://github.com/willvousden/ptemcee.git\n",
        "!pip install ./ptemcee"
      ],
      "metadata": {
        "id": "HaQ_v2Goclov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import healpy as hp\n",
        "import ptemcee\n",
        "import corner\n",
        "import lisaconstants\n",
        "from h5py import File\n",
        "\n",
        "from scipy.signal import welch\n",
        "from scipy.interpolate import interp1d\n",
        "import backgrounds\n",
        "\n",
        "from ptplot.science.calculate_powerspectrum import PowerSpectrum\n",
        "from lisaorbits import EqualArmlengthOrbits\n",
        "from lisagwresponse import StochasticBackground, psd\n",
        "from lisainstrument import Instrument\n",
        "from lisainstrument.containers import ForEachMOSA\n",
        "from pytdi import Data, michelson\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "9fxhPXy6cHE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Generate an orbit file"
      ],
      "metadata": {
        "id": "RiaTamp9b6o8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for outputs\n",
        "!mkdir data"
      ],
      "metadata": {
        "id": "6eqDmNLhce88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set directory for outputs\n",
        "BASEDIR = './data'\n",
        "# Set to true for quick tests\n",
        "QUICKTEST = True"
      ],
      "metadata": {
        "id": "l0PXn8G3ct5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the orbit simulation duration\n",
        "a_day = 24 * 3600 # s\n",
        "a_year = 365.25 * a_day # s\n",
        "duration = 2 * a_year\n",
        "# Set orbit initial and sampling time\n",
        "orbits_t0 = 0\n",
        "orbits_dt = 100000\n",
        "# We use a 2 year orbit (to allow for margin)\n",
        "orbits_size = int(duration// orbits_dt) + 1\n",
        "orbits_path = os.path.join(BASEDIR, 'orbits.h5')\n",
        "# Create an orbit object\n",
        "orbits = EqualArmlengthOrbits(\n",
        "    t_init=orbits_t0\n",
        ")"
      ],
      "metadata": {
        "id": "iUjZqph-c0bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove file if it exists\n",
        "if os.path.exists(orbits_path):\n",
        "    os.remove(orbits_path)\n",
        "# Generate and write orbit file\n",
        "orbits.write(orbits_path, dt=orbits_dt, size=orbits_size, mode='w')"
      ],
      "metadata": {
        "id": "Plo7rH5ec9ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read orbit file\n",
        "with File(orbits_path, 'r') as hdf:\n",
        "\n",
        "    t = orbits_t0 + np.arange(orbits_size) * orbits_dt\n",
        "\n",
        "    sc_positions = hdf['tcb/x'][:]\n",
        "    ltts = hdf['tcb/ltt'][:]\n",
        "    pprs = hdf['tps/ppr'][:]\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "    plt.subplot(311)\n",
        "    for i, coord in enumerate('xyz'):\n",
        "        plt.plot(t, sc_positions[:, 0, i], label=rf'${coord}$')\n",
        "    plt.ylabel('Spacecraft 1 [m]')\n",
        "    plt.title('Spacecraft positions')\n",
        "    plt.legend()\n",
        "    plt.subplot(312)\n",
        "    for i, coord in enumerate('xyz'):\n",
        "        plt.plot(t, sc_positions[:, 1, i], label=rf'${coord}$')\n",
        "    plt.ylabel('Spacecraft 2 [m]')\n",
        "    plt.legend()\n",
        "    plt.subplot(313)\n",
        "    for i, coord in enumerate('xyz'):\n",
        "        plt.plot(t, sc_positions[:, 2, i], label=rf'${coord}$')\n",
        "    plt.ylabel('Spacecraft 3 [m]')\n",
        "    plt.xlabel('Time [s]')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(111)\n",
        "    plt.plot(t, ltts)\n",
        "    plt.ylabel('LTT [s]')\n",
        "    plt.xlabel('Time [s]')\n",
        "    plt.title('Light travel time')"
      ],
      "metadata": {
        "id": "o8RG_-I_dRgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download and check signal data"
      ],
      "metadata": {
        "id": "Mr_z4u42ebpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Get data from LDC\n",
        "\n",
        "We dowload a dataset containing the TDI measurements of a stochastic gravitational wave background (SGWB) from a first-order phase transition happening in the early universe."
      ],
      "metadata": {
        "id": "JC7BBJNCgD2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We download a year-long dataset from the LDC website\n",
        "# !wget \"https://lisa-ldc.lal.in2p3.fr/media/uploads/cosmo/fopt-1b/tdi.h5\"\n",
        "!gdown 1VarTWIEtomHNWTQoikdnXU9XX93xDkBB\n",
        "!mv tdi.h5 data/tdi_gw.h5"
      ],
      "metadata": {
        "id": "TL7xjz23egHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXeMurVuspcy"
      },
      "outputs": [],
      "source": [
        "# Load the LDC SGWB dataset\n",
        "ldc_data_path = f'{BASEDIR}/tdi_gw.h5'\n",
        "with File(ldc_data_path, 'r') as hdf:\n",
        "    # Hubble constant\n",
        "    H0 = 3.24E-18\n",
        "    # The original dataset was missing a factor of sqrt{H0}\n",
        "    x2_gw_ldc = hdf['X2'][:] * np.sqrt(H0)\n",
        "    y2_gw_ldc = hdf['Y2'][:] * np.sqrt(H0)\n",
        "    z2_gw_ldc = hdf['Z2'][:] * np.sqrt(H0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCSvVYZOIrto"
      },
      "outputs": [],
      "source": [
        "def asd(x, fs, **kwargs):\n",
        "    \"\"\"Compute ASD from time series.\n",
        "\n",
        "    Args:\n",
        "        x (array): time series\n",
        "        fs (float): sampling frequency [Hz]\n",
        "        kwargs: keyword arguments passed to scipy.signal.welch\n",
        "    \"\"\"\n",
        "    if 'window' not in kwargs:\n",
        "        kwargs['window'] = ('kaiser', 30)\n",
        "    if 'nperseg' not in kwargs:\n",
        "        kwargs['nperseg'] = 2**18\n",
        "    if 'detrend' not in kwargs:\n",
        "        kwargs['detrend'] = None\n",
        "    freq, psd = welch(x, fs, **kwargs)\n",
        "    return freq[5:], np.sqrt(psd[5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPEeKsFHxXfx"
      },
      "outputs": [],
      "source": [
        "# Choose the size of the Welch segments\n",
        "nperseg = 2**17\n",
        "# Choose the segment overlap\n",
        "noverlap = nperseg // 2\n",
        "# Sampling frequency\n",
        "tdi_fs = 0.5 # Hz\n",
        "# Compute periodogram\n",
        "f, asd_x2 = asd(x2_gw_ldc[500:-500], tdi_fs, nperseg=nperseg,\n",
        "                window=\"hann\", noverlap=noverlap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYpcwhQ5EK5r"
      },
      "source": [
        "### 2.2 Define the stochastic background\n",
        "\n",
        "We use `ptplot` [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6949107.svg)](https://doi.org/10.5281/zenodo.6949107) (<https://www.ptplot.org>,\n",
        " Weir 2023) to compute the energy density power spectrum of a stochastic background due to first-order phase transitions (see Caprini et al 2021).\n",
        "\n",
        "We use values used in Fig. 6 of the Cosmology with LISA white paper (SNR of 10):\n",
        "\n",
        "$$v_w = 0.9,$$\n",
        "$$\\alpha = 0.1,$$\n",
        "$$\\beta / H = 50,$$\n",
        "$$T_\\star = 200 \\, \\text{GeV},$$\n",
        "$$g_\\star = 100.$$\n",
        "\n",
        "The tools gives $h^2 \\Omega(f)$. We convert to a one-sided power density spectral density with\n",
        "\n",
        "$$S_h(f) = h^2 \\Omega(f) \\frac{3 (H_0/h)^2}{4 \\pi^2 f^3},$$\n",
        "\n",
        "with $H_0/h = 100 \\, \\text{km} \\text{s}^{-1} \\text{Mpc}^{-1} \\approx 3.24 \\times 10^{-18} \\text{s}^{-1}$.\n",
        "\n",
        "We can compute the total energy in the sky and divide up into $N$ pixels, and 2 polarizations, to get the energy in each pixel,\n",
        "\n",
        "$$S_\\text{pixel}(f) = \\frac{4 \\pi}{2 N} S_h(f).$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We offset the signal t0 to have orbits information at emission time\n",
        "response_t0 = orbits_t0 + 100.0 # seconds\n",
        "response_fs = tdi_fs\n",
        "response_dt = 1 / response_fs\n",
        "# Generate 1 year dataset\n",
        "response_duration = a_day if QUICKTEST else a_year\n",
        "response_size = int(response_duration // response_dt) + 1\n",
        "response_nside = 4 if QUICKTEST else 8\n",
        "response_npix = hp.nside2npix(response_nside)\n",
        "response_path = os.path.join(BASEDIR, 'response.h5')\n",
        "# Specifications of the stochastic background (energy density)\n",
        "spectrum = PowerSpectrum(vw=0.9, alpha=0.1, BetaoverH=50, Tstar=200, gstar=100)\n",
        "h2_Omega = lambda f: spectrum.power_spectrum(f)\n",
        "# Conversion to one-sided power density spectral density\n",
        "energy_density_psd = lambda f: h2_Omega(f) * (3 * H0 ** 2) / (4 * np.pi**2 * f**3)\n",
        "# Conversion to one-sided power spectral density per pixel per polarization\n",
        "pixel_psd = lambda f: energy_density_psd(f) * (4 * np.pi) / (2 * response_npix)"
      ],
      "metadata": {
        "id": "yELWUidogXhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Compute the response model"
      ],
      "metadata": {
        "id": "SCNhWIPZvTL_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlk40MONjDsE"
      },
      "source": [
        "The sky-averaged single-link response to gravitational waves can be computed numerically, although low-frequency approximations exist. See, for example, Babak et al., 2021 https://arxiv.org/abs/2108.01167\n",
        "\n",
        "Here we use the analysis code delelopped in [Baghi et al. 2023](https://iopscience.iop.org/article/10.1088/1475-7516/2023/04/066).\n",
        "The SGWB PSD can be written as\n",
        "$$\n",
        "S_{X2, \\mathrm{gw}}(f) = S_{h}(f) R_{X2}(f)\n",
        "$$\n",
        "where $R$ is the sky-averaged response function for TDI X2:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "R_{X2}\\left(f, t_0\\right) & = R_{X2, +}\\left(f, t_0\\right) + R_{X2, \\times}\\left(f, t_0\\right) \\\\\n",
        "R_{X2, p}\\left(f, t_0\\right) & = \\int G_{X2, p}\\left(f, t_0, \\hat{\\mathbf{k}}\\right) G_{X2, p}^*\\left(f, t_0, \\hat{\\mathbf{k}}\\right) \\mathrm{d}^2 \\hat{\\mathbf{k}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "where $G_{X2}$ is a time and frequency dependent kernel encoding the antenna pattern."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of the time series\n",
        "data_size = x2_gw_ldc.size"
      ],
      "metadata": {
        "id": "b41nKf2Rv5Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qwz3ZFDr5cem"
      },
      "outputs": [],
      "source": [
        "# Instantiate the GW response analysis model\n",
        "npixels = hp.nside2npix(8)\n",
        "# Create a normalized map distributing the power accross the sky\n",
        "skymap = np.ones(npixels) * np.sqrt(4 * np.pi / (2*npixels))\n",
        "# Instantiate the SGWB object\n",
        "sgwb_cls = backgrounds.StochasticBackgroundResponse(skymap, orbits=orbits_path)\n",
        "# Create a coarse frequency grid where to compute the response\n",
        "freq_grid = np.exp(np.linspace(np.log(tdi_fs/data_size), np.log(tdi_fs/2), 2000))\n",
        "# Compute the response matrix for XYZ\n",
        "g_mat_xyz = sgwb_cls.compute_tdi_kernel(freq_grid, response_t0, tdi_var='xyz',\n",
        "                                        gen='2.0', parallel=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUpLpGOkog0L"
      },
      "outputs": [],
      "source": [
        "# Compute the SGWB PSD\n",
        "sh = energy_density_psd(f)\n",
        "# Build the sky-averaged GW response function by interpolating\n",
        "r_function = interp1d(freq_grid, g_mat_xyz[:, 0, 0].real, kind=\"cubic\",\n",
        "                      fill_value=\"extrapolate\")\n",
        "# Compute the TDI response to the SGWB\n",
        "tdi_model_gw = np.sqrt(sh * r_function(f))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Compare with the data periodogram"
      ],
      "metadata": {
        "id": "rfDHiL9fwPNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, axes = plt.subplots(2, 1, figsize=(12, 7), sharex=True,\n",
        "                       gridspec_kw={'height_ratios': [2, 1]})\n",
        "\n",
        "axes[0].loglog(f, asd_x2, label='X2')\n",
        "axes[0].loglog(f, tdi_model_gw, color='black', lw=2, label='model')\n",
        "axes[0].set_ylim(1E-26, 1E-20)\n",
        "axes[0].set_ylabel(r'TDI ASD [$\\mathrm{Hz^{-1/2}}$]')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].loglog(f, asd_x2 / tdi_model_gw, label='X2')\n",
        "axes[1].set_ylim(1E-2, 1E1)\n",
        "axes[1].set_xlabel('Frequency [Hz]')\n",
        "axes[1].set_ylabel(r'Whitened noise')\n",
        "axes[1].legend()"
      ],
      "metadata": {
        "id": "gQJ9zZL32QLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Download and check noise data"
      ],
      "metadata": {
        "id": "PvhtBMCJ7C-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Get data from LDC"
      ],
      "metadata": {
        "id": "gJBDpjWw_WyQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOI7FobM6C62"
      },
      "outputs": [],
      "source": [
        "# We can either use the dataset we just simulated, or download a year-long dataset from the LDC website\n",
        "# !wget \"https://lisa-ldc.lal.in2p3.fr/media/uploads/cosmo/noise-1a/tdi.h5\"\n",
        "!gdown 1DwRUzJ1JZZRmjXp1ZSL8JfvpvB5lKuKi\n",
        "!mv tdi.h5 data/tdi_noise.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrX-pifJ5cem"
      },
      "outputs": [],
      "source": [
        "# Similarly, instead of analysing the noise we generated, we download a year-long simulation.\n",
        "ldc_noise_path = f'{BASEDIR}/tdi_noise.h5'\n",
        "\n",
        "with File(ldc_noise_path, 'r') as hdf:\n",
        "    x2_noise_ldc = hdf['X2'][:]\n",
        "    y2_noise_ldc = hdf['Y2'][:]\n",
        "    z2_noise_ldc = hdf['Z2'][:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Define the noise model"
      ],
      "metadata": {
        "id": "YhP7aDDy_tuD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKWPjcCyRsQM"
      },
      "source": [
        "#### OMS noise analytical model\n",
        "\n",
        "In the inter-spacecraft interferometer (ISI, or science) carrier beatnotes, we should see the optical metrology system (OMS) noise. In terms of displacement, it's given by\n",
        "$$\n",
        "S_\\text{oms}^\\text{m}(f) = A^2 \\Big[ 1 + \\Big(\\frac{f_\\text{knee}}{f}\\Big)^4 \\Big].\n",
        "$$\n",
        "Multiplying by $(2\\pi f / c)^2$ to express it as fractional frequency deviations, we can obtain the equivalent frequency shift by adding the $\\nu_0^2$​ factor,\n",
        "$$\n",
        "S_\\text{oms}^\\text{Hz}(f) = \\Big(\\frac{2\\pi f \\nu_0}{c}\\Big)^2 S_\\text{oms}^\\text{m}(f).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv2AKzkJSR6M"
      },
      "outputs": [],
      "source": [
        "from lisaconstants import c\n",
        "\n",
        "def oms_in_isi_carrier(freq, instru, mosa='12'):\n",
        "    \"\"\"Model for OMS noise PSD in ISI carrier beatnote fluctuations.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    asd = instru.oms_isi_carrier_asds[mosa]\n",
        "    fknee = instru.oms_fknees[mosa]\n",
        "    psd_meters = asd**2 * (1 + (fknee / freq)**4)\n",
        "    psd_hertz = (2 * np.pi * freq * instru.central_freq / c)**2 * psd_meters\n",
        "    return np.sqrt(psd_hertz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2dI-TaOSlQa"
      },
      "source": [
        "#### TM noise analytical models\n",
        "\n",
        "In the test-mass interferometer (TMI) carrier beatnotes, we should see the test-mass noise. In terms of acceleration,\n",
        "$$S_\\delta^{\\text{m}\\,\\text{s}^{-2}}(f) = A^2 [ 1 + \\Big(\\frac{f_\\text{knee}}{f}\\Big)^2 ].$$\n",
        "Multiplying by $1/(2 \\pi f )^2$ yields the noise as a velocity, and then dividing by c yields the noise as a Doppler shift. One needs to scale this by $2\\nu_{0}$​ to get the equivalent frequency shift (the factor 2 is for the bouncing on the test mass),\n",
        "$$S_\\delta^\\text{Hz}(f) = \\Big(\\frac{2 \\nu_0}{2 \\pi c f}\\Big)^2 S_\\delta^{\\text{m}\\,\\text{s}^{-2}}(f).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHY1CuENSkJt"
      },
      "outputs": [],
      "source": [
        "def testmass_in_tmi_carrier(freq, instru, mosa='12'):\n",
        "    \"\"\"Model for TM noise PSD in TMI carrier beatnote fluctuations.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    asd = instru.testmass_asds[mosa]\n",
        "    fknee = instru.testmass_fknees[mosa]\n",
        "    psd_acc = asd**2 * (1 + (fknee / freq)**2)\n",
        "    psd_hertz = (2 * instru.central_freq / (2 * np.pi * c * freq))**2 * psd_acc\n",
        "    return np.sqrt(psd_hertz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLep-Ni8WgdA"
      },
      "source": [
        "#### TDI instrumental noise model\n",
        "\n",
        "The transfer functions through TDI are taken from [Dam Quang et al](https://arxiv.org/pdf/2211.02539.pdf). We use the common factor that depends on the average arm length L (in the code, directly given in seconds by the PPRs),\n",
        "$$C_{XX}(f) = 16 \\sin^2(2 \\pi f L / c) \\sin^2(4 \\pi f L / c).$$\n",
        "\n",
        "The transfer function for the ISI OMS noise PSD is given by\n",
        "$$4 C_{XX}(f).$$\n",
        "\n",
        "The transfer function for the test-mass noise PSD reads\n",
        "$$C_{XX}(f) [3 + \\cos(4 \\pi f L / c)].$$\n",
        "\n",
        "Note that the factor 2 has been removed since it's already included in the noise PSD.\n",
        "\n",
        "Therefore, the total noise model can be written as\n",
        "$$\n",
        "S_{X2, n}(f) = S_{X2, \\mathrm{oms}}(f) + S_{X2, \\mathrm{tm}}(f)\n",
        "$$\n",
        "with\n",
        "$$\n",
        "\\begin{align}\n",
        "S_{X2, \\mathrm{oms}}(f) & = 4 C_{XX}(f) S_{\\mathrm{oms}}(f) \\\\\n",
        "S_{X2, \\mathrm{tm}}(f) & = C_{XX}(f) [3 + \\cos(4 \\pi f L / c)] S_{\\mathrm{\\delta}}(f)\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTuwg4izWc60"
      },
      "outputs": [],
      "source": [
        "def tdi_common(freq, instru, mosa='12'):\n",
        "    \"\"\"TDI common factor.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "\n",
        "    Reference: https://journals.aps.org/prd/abstract/10.1103/PhysRevD.108.082004\n",
        "\n",
        "    \"\"\"\n",
        "    armlength = np.mean(instru.pprs[mosa])\n",
        "    return 16 * np.sin(2 * np.pi * freq * armlength)**2 \\\n",
        "        * np.sin(4 * np.pi * freq * armlength)**2\n",
        "\n",
        "\n",
        "def tdi_tf_oms(freq, instru, mosa='12'):\n",
        "    \"\"\"TDI transfer function for ISI OMS noise.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    psd = 4 * tdi_common(freq, instru, mosa)\n",
        "    return np.sqrt(psd)\n",
        "\n",
        "\n",
        "def tdi_tf_testmass(freq, instru, mosa='12'):\n",
        "    \"\"\"TDI transfer function for test mass noise.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    armlength = np.mean(instru.pprs[mosa])\n",
        "    psd = tdi_common(freq, instru, mosa) * (3 + np.cos(4 * np.pi * freq * armlength))\n",
        "    return np.sqrt(psd)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Compute the noise model"
      ],
      "metadata": {
        "id": "4mHbqJqI_c4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXEQBfAiPqFZ"
      },
      "outputs": [],
      "source": [
        "# We offset the instrument t0 to have orbits information at emission time\n",
        "instru_t0 = orbits_t0 + 100.0\n",
        "instru_fs = response_fs\n",
        "instru_dt = 1 / instru_fs\n",
        "# Generate 1 year dataset\n",
        "instru_duration = response_duration\n",
        "instru_size = int(instru_duration // instru_dt) + 1\n",
        "# Instantiate the instrument class\n",
        "instru = Instrument(\n",
        "    t0=instru_t0,\n",
        "    dt=instru_dt,\n",
        "    size=instru_size,\n",
        "    physics_upsampling=1,\n",
        "    aafilter=None,\n",
        "    lock='six',\n",
        "    orbits=orbits_path,\n",
        "    orbit_dataset='tcb/ltt',\n",
        ")\n",
        "\n",
        "instru.disable_dopplers()\n",
        "instru.disable_all_noises()\n",
        "# Noise curves from LDC Spritz\n",
        "instru.testmass_asds = ForEachMOSA(2.4E-15)\n",
        "instru.oms_isi_carrier_asds = ForEachMOSA(7.9e-12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCICE 1**: Based on the functions `tdi_tf_testmass`, `testmass_in_tmi_carrier`, `tdi_tf_oms`, `oms_in_isi_carrier` defined below, write down the full ASD (or PSD) model for TDI $X_2$."
      ],
      "metadata": {
        "id": "B40uTBCiUcUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2blqT_0QsZT"
      },
      "outputs": [],
      "source": [
        "### EXERCICE 1 ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Compare with the data periodogram"
      ],
      "metadata": {
        "id": "1b8YJlTBEjP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43FgvwaiN0Dr"
      },
      "outputs": [],
      "source": [
        "# Add noise and signal after converting everything in relative frequency deviations\n",
        "x2 = x2_noise_ldc / instru.central_freq + x2_gw_ldc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the periodogram of noise + signal data\n",
        "f, asd_x2 = asd(x2[500:-500], tdi_fs, nperseg=nperseg, window=\"hann\", noverlap=noverlap)"
      ],
      "metadata": {
        "id": "RYGL9URN7EYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcorCjyqQaBi"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 1, figsize=(12, 7))\n",
        "\n",
        "axes.loglog(f, asd_x2, label='X2')\n",
        "axes.loglog(f, tdi_model, color='black', lw=2, label='Total model')\n",
        "axes.loglog(f, tdi_model_gw, color='tab:red', lw=2, label='GW model')\n",
        "axes.loglog(f, model_noise/instru.central_freq, color='gray', lw=2, linestyle=\"dashed\", label='Noise model')\n",
        "axes.set_ylim(1E-25, 1E-18)\n",
        "axes.set_xlim(1E-4, 1E-1)\n",
        "axes.set_ylabel(r'TDI ASD [$\\mathrm{Hz^{-1/2}}$]')\n",
        "axes.set_xlabel(\"Frequency [Hz]\")\n",
        "axes.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDacnFXR4UwX"
      },
      "source": [
        "## 4. Data analysis: parameter estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEjSIbtc4ZOX"
      },
      "source": [
        "### 4.1 Noise-only parameter estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9-bECcPagh4"
      },
      "source": [
        "The Welch periodogram is approximately proportional to a chi squared distribution with $\\nu$ degrees of freedom:\n",
        "$$\n",
        "\\bar{P}(f) \\sim \\frac{1}{\\nu} S(f) \\chi^2_{\\nu}\n",
        "$$\n",
        "The effetive number of degrees of freedom depends on the type of tappering windows, as well as\n",
        "the number of segments and their overlaps. See, for example, [Solomon 1991](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.osti.gov/servlets/purl/5688766&ved=2ahUKEwjtw8rj3MmIAxXlgf0HHREsGyEQFnoECBgQAQ&usg=AOvVaw32eeZggUFFfstzQ2jIJnSF).\n",
        "\n",
        "One can compute it as\n",
        "$$\n",
        "\\nu = \\frac{2 \\cdot \\mathrm{K}}{1+\\sum_{\\mathrm{k}=1}^{\\mathrm{K}-1} \\frac{\\mathrm{K}-\\mathrm{k}}{\\mathrm{K}} \\rho(\\mathrm{k}, \\mathrm{S})}\n",
        "$$\n",
        "where\n",
        "$$\n",
        "\\rho(k, S)= \\begin{cases}\\left(\\frac{1}{\\mathrm{NPG}} \\sum_{m=1}^{M-k S} w(m) w(m+k S)\\right)^2, & 1 \\leq k \\leq \\operatorname{int}(M / S) \\\\ 0, & S \\geq M\\end{cases}\n",
        "$$\n",
        "Here,\n",
        "* $w$ is the window function\n",
        "* $N$ is the size of the full time series\n",
        "* $K$ is the number of segments\n",
        "* $M$ is the number of points in each segment\n",
        "* $S$ is the number of points to shift between segments, to allow for overlaps\n",
        "* $\\mathrm{NPG} = \\sum_{n=1}^{M} w_{n}^2$ is the noise power gain\n",
        "\n",
        "The likelihood is therefore given by (see [Hindmarsh et al 2024](https://arxiv.org/abs/2406.04894))\n",
        "$$\n",
        "\\mathcal{L}(\\bar{P} \\mid S)=\\prod_{n=0}^{M-1} \\frac{1}{2^{(\\nu / 2)} \\Gamma(\\nu / 2)}\\left(\\frac{\\nu}{S\\left(f_n\\right)}\\right)\\left(\\nu \\frac{\\bar{P}\\left(f_n\\right)}{S\\left(f_n\\right)}\\right)^{(\\nu / 2)-1} \\exp \\left(-\\frac{\\nu}{2} \\frac{\\bar{P}\\left(f_n\\right)}{S\\left(f_n\\right)}\\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_9xRFhpdJJ"
      },
      "source": [
        "To start with, we use a parametrized noise model with two parameters $A_{\\mathrm{oms}}$ and $A_{\\mathrm{tm}}$, determining the amplitude of the test-mass noise contribution and the optical metrology system noise contribution to the total noise, so that:\n",
        "$$\n",
        "S(f) = A_{\\mathrm{oms}} S_{X2, \\mathrm{oms}}(f) + A_{\\mathrm{tm}} S_{X2, \\mathrm{tm}}(f)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the likelihood for the noise model"
      ],
      "metadata": {
        "id": "lNoqMo1KD3Oi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHaDI59K4lTY"
      },
      "outputs": [],
      "source": [
        "class Likelihood:\n",
        "\n",
        "    def __init__(self, freq, asd, nperseg, data_size, noverlap=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        freq : ndarray\n",
        "            Frequency vector\n",
        "        asd : ndarray\n",
        "            ASD vector\n",
        "        nperseg : int\n",
        "            number of points in each segment\n",
        "        data_size : int\n",
        "            number of data points in the time series\n",
        "        noverlap : int\n",
        "            number of points to shift between segments, to allow for overlaps\n",
        "\n",
        "        References\n",
        "        ----------\n",
        "        Hindmarsh et al., https://arxiv.org/abs/2406.04894\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_size = data_size\n",
        "        self.x_per = np.abs(asd)**2\n",
        "        self.freq = freq\n",
        "        self.nperseg = nperseg\n",
        "\n",
        "        # Effective number of degrees of freedom for the chi squared\n",
        "        # distribution of the Welch periodogram with a 50% overlap using the\n",
        "        # Hann window\n",
        "\n",
        "        # Number of windows\n",
        "        if noverlap==0:\n",
        "            self.nw = int(self.data_size/self.nperseg)\n",
        "            self.nu = 2 * self.nw\n",
        "        else:\n",
        "            # Only valid for the Hann window\n",
        "            self.nw = 2 * self.data_size / self. nperseg - 1\n",
        "            self.nu = (36/19) * self.nw**2 / (self.nw - 1)\n",
        "\n",
        "        # OMS noise ASD in relative frequency deviations\n",
        "        self.oms_psd = (tdi_tf_oms(self.freq, instru) * oms_in_isi_carrier(self.freq, instru) / instru.central_freq)**2\n",
        "        # TM noise ASD in relative frequency deviations\n",
        "        self.testmass_psd = (tdi_tf_testmass(self.freq, instru) * testmass_in_tmi_carrier(self.freq, instru) / instru.central_freq)**2\n",
        "\n",
        "    def evaluate_noise_psd(self, params_n):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        params_n : ndarray\n",
        "            Noise model parameters: amplitude of OMS noise + amplitude of TM\n",
        "\n",
        "        \"\"\"\n",
        "        # Noise part\n",
        "        psd = params_n[0] * self.oms_psd + params_n[1] * self.testmass_psd\n",
        "\n",
        "        return psd\n",
        "\n",
        "    def evaluate_loglike(self, params):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        params : ndarray\n",
        "            Noise model parameters: amplitude of OMS noise + amplitude of TM\n",
        "        \"\"\"\n",
        "\n",
        "        s_xx = self.evaluate_noise_psd(params)\n",
        "\n",
        "        # loglike = -np.sum(self.x_per / s_xx + np.log(s_xx))\n",
        "        loglike = np.sum(-(self.nu/2) * self.x_per / s_xx\n",
        "                         +(self.nu/2 - 1) * np.log(self.x_per / s_xx)\n",
        "                         - np.log(s_xx))\n",
        "        return np.real(loglike)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHhvx8zf5cen"
      },
      "outputs": [],
      "source": [
        "# We select the frequency bandwidth we want to analyze\n",
        "f, asd_x2_noise = asd(x2_noise_ldc[500:-500] / instru.central_freq, tdi_fs,\n",
        "                      nperseg=nperseg,\n",
        "                      window=\"hann\", noverlap=noverlap)\n",
        "iband = np.where((f>=1e-4) & (f<=1e-2))\n",
        "f_band = f[iband]\n",
        "asd_x2_noise_band = asd_x2_noise[iband]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHBMfIbjoD5H"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 1, figsize=(12, 7))\n",
        "\n",
        "axes.loglog(f_band, asd_x2_noise_band, label='X2')\n",
        "axes.loglog(f_band, model_noise[iband]/instru.central_freq,\n",
        "            color='black', lw=2, label='total noise model')\n",
        "axes.set_ylabel(r'TDI ASD [Hz/$\\sqrt{\\mathrm{Hz}}$]')\n",
        "axes.set_xlabel(\"Frequency [Hz]\")\n",
        "axes.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r7VjNnE3ymB"
      },
      "outputs": [],
      "source": [
        "# Instantiate the likelihood class\n",
        "loglike = Likelihood(f_band, asd_x2_noise_band, nperseg, len(x2[500:-500]), noverlap=noverlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUrAfE_xfObm"
      },
      "outputs": [],
      "source": [
        "# Test of the likelihood\n",
        "params = np.array([1, 1])\n",
        "loglike.evaluate_loglike(params)\n",
        "# List of deviations from true value for OMS noise amplitude\n",
        "param1_list = np.linspace(0.5, 2, 50)\n",
        "loglike_list = [loglike.evaluate_loglike(np.asarray([p, 1.0]))\n",
        "for p in param1_list]\n",
        "\n",
        "# Plot the loglikelihood values vs OMS noise parameter deviations\n",
        "plt.figure(0)\n",
        "plt.plot(param1_list - 1.0, loglike_list)\n",
        "plt.xlabel('$\\Delta$OMS noise')\n",
        "plt.ylabel('Log-likelihood')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVvf-LYziLNx"
      },
      "outputs": [],
      "source": [
        "# List of deviations from true value for TM noise amplitude\n",
        "param2_list = np.linspace(0.5, 2, 50)\n",
        "loglike_list = [loglike.evaluate_loglike(np.asarray([1.0, p]))\n",
        "for p in param2_list]\n",
        "\n",
        "# Plot the loglikelihood values vs OMS noise parameter deviations\n",
        "plt.figure(0)\n",
        "plt.plot(param2_list - 1.0, loglike_list)\n",
        "plt.xlabel('$\\Delta$TM noise')\n",
        "plt.ylabel('Log-likelihood')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the prior"
      ],
      "metadata": {
        "id": "SDBRQ_ptDwIl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h63ZP20cyTOe"
      },
      "outputs": [],
      "source": [
        "class UniformPrior:\n",
        "\n",
        "    def __init__(self, a, b):\n",
        "\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        if isinstance(a, np.ndarray):\n",
        "            self.ndim = self.a.size\n",
        "        elif isinstance(a, list):\n",
        "            self.ndim = len(a)\n",
        "        else:\n",
        "            self.ndim = 1\n",
        "\n",
        "    def evaluate(self, x):\n",
        "\n",
        "        # First check that knots are sorted\n",
        "        if (np.all(self.a < x)) & (np.all(self.b > x)):\n",
        "            # Check that values are within bounds and knots are sorted\n",
        "            return 0.0  # knot_prior_cls.evaluate(knots)\n",
        "        else:\n",
        "            return -np.inf\n",
        "\n",
        "    def initialize_single_param(self):\n",
        "        \"\"\"Initialize one parameter state\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        p_0 : ndarray\n",
        "            parameter vector, size ndim\n",
        "        \"\"\"\n",
        "\n",
        "        p_0 = np.random.uniform(low=self.a, high=self.b)\n",
        "\n",
        "        return np.atleast_1d(p_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMihej2UzbrE"
      },
      "outputs": [],
      "source": [
        "a = np.asarray([0.5, 0.5])\n",
        "b = np.asarray([2, 2])\n",
        "\n",
        "logprior = UniformPrior(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiom3a5dztoD"
      },
      "outputs": [],
      "source": [
        "# Set up the sampler\n",
        "nwalkers = 8\n",
        "ntemps = 5\n",
        "ndim = 2\n",
        "niter = 2000\n",
        "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "from ptemcee.interruptible_pool import Pool\n",
        "mapper = Pool().map\n",
        "# mapper = map\n",
        "\n",
        "# Intialize the parameter state\n",
        "pos = np.random.uniform(low=a, high=b, size=(ntemps, nwalkers, ndim))\n",
        "# Instantiate the sampler\n",
        "sampler = ptemcee.Sampler(nwalkers, ndim, loglike.evaluate_loglike,\n",
        "                          logprior.evaluate,\n",
        "                          betas=ptemcee.make_ladder(ndim, ntemps=ntemps, Tmax=None),\n",
        "                          mapper=mapper)\n",
        "# Run the sampler\n",
        "# ensemble = sampler.sample(pos, rstate=np.random.get_state())\n",
        "chain = sampler.chain(pos)\n",
        "for counter, x in enumerate(chain.iterate(niter)):\n",
        "    if counter % 100 == 0:\n",
        "        print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBsjvGdi5v9H"
      },
      "outputs": [],
      "source": [
        "print(chain.x.shape)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(311)\n",
        "plt.plot(np.arange(niter), chain.x[:, 0, 0, 0])\n",
        "plt.ylabel('OMS noise amplitude')\n",
        "\n",
        "plt.subplot(312)\n",
        "plt.plot(np.arange(niter), chain.x[:, 0, 0, 1])\n",
        "plt.ylabel('TMI noise amplitude')\n",
        "plt.xlabel('Step')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMFPXHhz7aX9"
      },
      "outputs": [],
      "source": [
        "# Reshape samples\n",
        "burnin = 1000\n",
        "nwalkers = chain.x.shape[2]\n",
        "i_max = chain.x.shape[0]\n",
        "samples_plot = chain.x[burnin:i_max, 0, :, :].reshape((nwalkers*(i_max-burnin),\n",
        "                                                       chain.x.shape[-1]))\n",
        "print(samples_plot.shape)\n",
        "# Plot intrinsic parameters\n",
        "figure = corner.corner(samples_plot[:, 0:4],\n",
        "                       labels=[r\"$A_{\\mathrm{OMS}}$\", r\"$A_{\\mathrm{TM}}$\"],\n",
        "                       show_titles=True,\n",
        "                       truths=np.ones(2),\n",
        "                       title_kwargs={\"fontsize\": 12})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p49mdW2q8Lqp"
      },
      "source": [
        "### 4.2 Signal + noise parameter estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEGM12l15vqC"
      },
      "source": [
        "Now we analyse the data stream assuming the presence of a stochastic background of cosmological origin. The PSD model of channel $X_2$ can now be written as\n",
        "$$\n",
        "S(f) = A_{\\mathrm{oms}} S_{X2, \\mathrm{oms}}(f) + A_{\\mathrm{tm}} S_{X2, \\mathrm{tm}}(f) + S_{X2, \\mathrm{gw}}(f, \\alpha_{\\mathrm{pt}})\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9TDlxDmhyi0"
      },
      "outputs": [],
      "source": [
        "# Now we consider a time series with a SGWB + noise\n",
        "asd_x2_band = asd_x2[iband]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waQILuxfiQjP"
      },
      "outputs": [],
      "source": [
        "_, axes = plt.subplots(1, 1, figsize=(12, 7))\n",
        "\n",
        "axes.loglog(f_band, asd_x2_band, label='X2')\n",
        "axes.loglog(f_band, model_noise[iband]/instru.central_freq,\n",
        "            color='black', lw=2, label='noise model')\n",
        "axes.loglog(f_band, tdi_model_gw[iband],\n",
        "            color='red', lw=2, label='GW model')\n",
        "axes.set_ylabel(r'TDI ASD [1/$\\sqrt{\\mathrm{Hz}}$]')\n",
        "axes.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCICE 2**: Modify the likelihood class below to include the GW signal into the model, governed by the parameter $\\alpha_{\\mathrm{pt}}$.\n",
        "\n",
        "*Help*: to update the GW background PSD model with a new value of $\\alpha_{\\mathrm{pt}}$, one can write:\n",
        "\n",
        "\n",
        "```\n",
        "spectrum.alpha = alpha_pt\n",
        "```\n"
      ],
      "metadata": {
        "id": "8m7juHgHdDNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxkokSt9SgEl"
      },
      "outputs": [],
      "source": [
        "### EXERCICE 2 ###\n",
        "\n",
        "class LikelihoodFull:\n",
        "\n",
        "    def __init__(self, freq, asd, nperseg, data_size, noverlap=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        freq : ndarray\n",
        "            Frequency vector\n",
        "        asd : ndarray\n",
        "            ASD vector\n",
        "        nperseg : int\n",
        "            number of points in each segment\n",
        "        data_size : int\n",
        "            number of data points in the time series\n",
        "        noverlap : int\n",
        "            number of points to shift between segments, to allow for overlaps\n",
        "\n",
        "        References\n",
        "        ----------\n",
        "        Hindmarsh et al., https://arxiv.org/abs/2406.04894\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_size = data_size\n",
        "        self.x_per = np.abs(asd)**2\n",
        "        self.freq = freq\n",
        "        self.nperseg = nperseg\n",
        "\n",
        "        # Effective number of degrees of freedom for the chi squared\n",
        "        # distribution of the Welch periodogram with a 50% overlap using the\n",
        "        # Hann window\n",
        "\n",
        "        # Number of windows\n",
        "        if noverlap==0:\n",
        "            self.nw = int(self.data_size/self.nperseg)\n",
        "            self.nu = 2 * self.nw\n",
        "        else:\n",
        "            # Only valid for the Hann window\n",
        "            self.nw = 2 * self.data_size / self. nperseg - 1\n",
        "            self.nu = (36/19) * self.nw**2 / (self.nw - 1)\n",
        "\n",
        "        # OMS noise ASD in relative frequency deviations\n",
        "        self.oms_psd = (tdi_tf_oms(self.freq, instru) * oms_in_isi_carrier(self.freq, instru) / instru.central_freq)**2\n",
        "        # TM noise ASD in relative frequency deviations\n",
        "        self.testmass_psd = (tdi_tf_testmass(self.freq, instru) * testmass_in_tmi_carrier(self.freq, instru) / instru.central_freq)**2\n",
        "\n",
        "        # Complete here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2v5UYKDisCq"
      },
      "outputs": [],
      "source": [
        "# Instantiate the likelihood class\n",
        "loglike = LikelihoodFull(f_band, asd_x2_band, nperseg, data_size,\n",
        "                         noverlap=noverlap)\n",
        "# Test of the likelihood\n",
        "params = np.array([1, 1, 0])\n",
        "loglike.evaluate_loglike(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-2u4SU7i9fz"
      },
      "outputs": [],
      "source": [
        "# List of deviations from true value for OMS noise amplitude\n",
        "param_gw_list = np.linspace(-1, 1, 50)\n",
        "loglike_list = [loglike.evaluate_loglike(np.asarray([1.0, 1.0, p]))\n",
        "for p in param_gw_list]\n",
        "\n",
        "# Plot the loglikelihood values vs GW parameter deviations\n",
        "plt.figure(0)\n",
        "plt.plot(param_gw_list, loglike_list)\n",
        "plt.xlabel('$\\Delta$SGWB amplitude')\n",
        "plt.ylabel('Log-likelihood')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RchogrD3jhSU"
      },
      "outputs": [],
      "source": [
        "# Prior bounds for noise and signal parameters\n",
        "a = np.asarray([0.5, 0.5, 0.0])\n",
        "b = np.asarray([2, 2, 1.0])\n",
        "logprior = UniformPrior(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW8vpBFYjhSW"
      },
      "outputs": [],
      "source": [
        "# Set up the sampler\n",
        "nwalkers = 12\n",
        "ntemps = 5\n",
        "ndim = 3\n",
        "niter = 2000\n",
        "# Intialize the parameter state\n",
        "pos = np.random.uniform(low=a, high=b, size=(ntemps, nwalkers, ndim))\n",
        "# Instantiate the sampler\n",
        "sampler = ptemcee.Sampler(nwalkers, ndim, loglike.evaluate_loglike,\n",
        "                          logprior.evaluate,\n",
        "                          betas=ptemcee.make_ladder(ndim, ntemps=ntemps,\n",
        "                                                    Tmax=None),\n",
        "                          mapper=mapper)\n",
        "# Run the sampler\n",
        "# ensemble = sampler.sample(pos, rstate=np.random.get_state())\n",
        "chain = sampler.chain(pos)\n",
        "for counter, x in enumerate(chain.iterate(niter)):\n",
        "    if counter % 100 == 0:\n",
        "        print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk5hQhbIj74r"
      },
      "outputs": [],
      "source": [
        "print(chain.x.shape)\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.subplot(311)\n",
        "plt.plot(np.arange(niter), chain.x[:, 0, 0, 0])\n",
        "plt.ylabel('OMS noise amplitude')\n",
        "\n",
        "plt.subplot(312)\n",
        "plt.plot(np.arange(niter), chain.x[:, 0, 0, 1])\n",
        "plt.ylabel('TM noise amplitude')\n",
        "plt.xlabel('Step')\n",
        "\n",
        "plt.subplot(313)\n",
        "plt.plot(np.arange(niter), chain.x[:, 0, 0, 2])\n",
        "plt.ylabel('SGWB amplitude')\n",
        "plt.xlabel('Step')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hakNHXn5kYv0"
      },
      "outputs": [],
      "source": [
        "# Reshape samples\n",
        "burnin = 1000\n",
        "nwalkers = chain.x.shape[2]\n",
        "i_max = chain.x.shape[0]\n",
        "samples_plot = chain.x[burnin:i_max, 0, :, :].reshape((nwalkers*(i_max-burnin),\n",
        "                                                       chain.x.shape[-1]))\n",
        "print(samples_plot.shape)\n",
        "# Plot intrinsic parameters\n",
        "figure = corner.corner(samples_plot[:, 0:4],\n",
        "                       labels=[r\"$A_{\\mathrm{oms}}$\", r\"$A_{\\mathrm{tm}}$\",\n",
        "                               r\"$\\alpha_{\\mathrm{pt}}$\"],\n",
        "                       show_titles=True,\n",
        "                       truths=np.asarray([1.0, 1.0, 0.1]),\n",
        "                       title_kwargs={\"fontsize\": 12})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Using more TDI channels"
      ],
      "metadata": {
        "id": "vCzd7w49pdoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXERCICE 3** Try writing a noise-only likelihood class that now analyse TDI channels A and E. We give some hints below."
      ],
      "metadata": {
        "id": "8VeMgWTjdXe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### EXERCICE 3 ###\n",
        "\n",
        "# We go from XYZ to AET by performing the following operation:\n",
        "def xyz2aet(x, y, z):\n",
        "    a,e,t = ((z - x)/np.sqrt(2.0),\n",
        "            (x - 2.0*y + z)/np.sqrt(6.0),\n",
        "            (x + y + z)/np.sqrt(3.0))\n",
        "    return a,e,t\n",
        "\n",
        "\n",
        "# The TDI PSD models for A, E, T are\n",
        "def tdi_tf_oms(freq, instru, mosa='12', tdi='AET'):\n",
        "    \"\"\"TDI transfer function for ISI OMS noise.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    if tdi=='XYZ':\n",
        "      psd = 4 * tdi_common(freq, instru)\n",
        "      return np.sqrt(psd)\n",
        "    elif tdi=='AET':\n",
        "      armlength = np.mean(instru.pprs[mosa])\n",
        "      psd_AE = 2 * tdi_common(freq, instru) * ( 2 + np.cos(2 * np.pi * freq * armlength))\n",
        "      psd_T = 4*tdi_common(freq, instru) * (1 - np.cos(2 * np.pi * freq * armlength))\n",
        "      return np.sqrt(psd_AE), np.sqrt(psd_T)\n",
        "\n",
        "def tdi_tf_testmass(freq, instru, mosa='12', tdi='AET'):\n",
        "    \"\"\"TDI transfer function for test mass noise.\n",
        "\n",
        "    Args:\n",
        "        freq (float): frequencies [Hz]\n",
        "        instru (Instrument): LISA instrument object\n",
        "    \"\"\"\n",
        "    armlength = np.mean(instru.pprs[mosa])\n",
        "    if tdi=='XYZ':\n",
        "      psd = tdi_common(freq, instru) * (3 + np.cos(4 * np.pi * freq * armlength))\n",
        "      return np.sqrt(psd)\n",
        "    elif tdi=='AET':\n",
        "      psd_AE = tdi_common(freq, instru) * (3 + 2*np.cos(2 * np.pi * freq * armlength) + np.cos(4 * np.pi * freq * armlength))\n",
        "      psd_T = 32*tdi_common(freq, instru) * np.sin(np.pi * freq * armlength)**4\n",
        "      return np.sqrt(psd_AE), np.sqrt(psd_T)"
      ],
      "metadata": {
        "id": "QHYLiMxQd37b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5oEPA8O6m4sd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}